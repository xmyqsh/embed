import torch
import torch.nn as nn
import torch.nn.functional as F
from embed.cv.cnn import ConvModule
from embed.cv.runner import auto_fp16

from embed.models import POSITION_DECODING_HEADS

from functools import partial

from .base_position_decoding_head import BasePositionDecodingHead

@POSITION_DECODING_HEADS.register_module()
class StandardSemanticPositionDecodingHead(BasePositionDecodingHead):
    r"""Standard Semantic Position Decoding Head.
    """

    def __init__(self, ignore_val=255,
                       **kwargs):
        super(StandardSemanticPositionDecodingHead, self).__init__(**kwargs)
        self.ignore_val = ignore_val

    def forward_train(self, x, gt_guided_idx_feat_sts,
                               gt_sem_label,
                               gt_sem_class,
                               num_sts):
        # TODO(ljm): around here
        gt_guided_idx_feat_st, gt_sem_label, num_sts = \
            self.get_targets(num_sts, gt_guided_idx_feat_sts, gt_sem_label)
        del gt_guided_idx_feat_sts
        gt_guided_sem = self.get_gt_guided_sems(x, num_sts, gt_guided_idx_feat_st)
        del gt_guided_idx_feat_st
        loss_sem_st = self.loss(gt_guided_sem, gt_sem_label, avg_factor=sum(num_sts))
        return dict(loss_sem_st=loss_sem_st)

    # TODO(ljm): parse args
    def post_process_pre(self, sem, cls, score, nums):
        # TODO(ljm): score is not used in the post process,
        #            Can we use it to improve the results?
        # FATAL(ljm): fix torch.ones to torch.range
        keeps = map(partial(torch.ones, dtype=torch.int32, device=cls.device), nums)
        return sem, cls.to(torch.int32), score, keeps

    def post_process_single_image(self, sem, cls, score, img_meta):
        # TODO(ljm): score is not used in the post process,
        #            Can we use it to improve the results?
        sem = self.post_process_single_image_rescale(sem, img_meta).argmax(dim=0)
        pred_sem = torch.zeros_like(sem, dtype=torch.uint8) + self.ignore_val
        for f, t in enumerate(cls):
            pred_sem[sem == f] = t
        # TODO(ljm): Should we try to filter stuff by stuff_area_limit here ?
        #            Hmm..., instance and sem_seg result could be regenerated by panoptic result, right ?
        #            Do as PanopticFPN do currently.
        #map(lambda f, t: pred_sem[sem == f] = t, *enumerate(cls))
        return dict(pred_sem=pred_sem, cls=cls)
